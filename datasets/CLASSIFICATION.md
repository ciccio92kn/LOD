# Image Classification Datasets

## General

* [ImageNet](http://image-net.org/index)
* [Tiny ImageNet](https://www.kaggle.com/c/tiny-imagenet)
* [mini ImageNet](https://github.com/yaoyao-liu/mini-imagenet-tools)
* [tiered ImageNet](https://github.com/yaoyao-liu/tiered-imagenet-tools)
* [ImageNet-32](https://github.com/PatrykChrabaszcz/Imagenet32_Scripts)
* [ImageNet-Sketch](https://github.com/HaohanWang/ImageNet-Sketch)
* [ImageNet-P](https://github.com/hendrycks/robustness)
* [CIFAR-10/100](https://www.cs.toronto.edu/~kriz/cifar.html)
* [Meta-Dataset](https://github.com/google-research/meta-dataset)
* [WebVision](https://data.vision.ee.ethz.ch/cvl/webvision/dataset2017.html)
* [ObjectNet](https://objectnet.dev/)
* [CINIC-10](https://github.com/BayesWatch/cinic-10)
* [Open Images](https://storage.googleapis.com/openimages/web/index.html)
* [Tencent ML-Images](https://github.com/Tencent/tencent-ml-images)
* [STL-10](https://cs.stanford.edu/~acoates/stl10/)
* [NUS-WIDE](https://lms.comp.nus.edu.sg/wp-content/uploads/2019/research/nuswide/NUS-WIDE.html)

## Objects

* [CORe50](https://vlomonaco.github.io/core50/)
* [Washington RGB-D](https://rgbd-dataset.cs.washington.edu/)
* [iCubWorld](https://robotology.github.io/iCubWorld/)
* [Open MIC](http://users.cecs.anu.edu.au/~koniusz/openmic-dataset/index.php)
* [ARID](https://www.acin.tuwien.ac.at/en/vision-for-robotics/software-tools/autonomous-robot-indoor-dataset/)
* [GOZ](https://github.com/TristHas/GOZ)
* [RP2K](https://www.pinlandata.com/rp2k_dataset)
* [Caltech-101](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)
* [Caltech-256](http://www.vision.caltech.edu/Image_Datasets/Caltech256/)
* [Office-31](https://people.eecs.berkeley.edu/~jhoffman/domainadapt/)
* [YFCC100M](https://paperswithcode.com/dataset/yfcc100m)
* [Office-Home](https://www.hemanthdv.org/officeHomeDataset.html)

## Characters

* [MNIST](http://yann.lecun.com/exdb/mnist/)
* [EMNIST](https://www.nist.gov/itl/products-and-services/emnist-dataset)
* [QMNIST](https://github.com/facebookresearch/qmnist)
* [SVHN](http://ufldl.stanford.edu/housenumbers/)
* [HASY](https://zenodo.org/record/259444)
* [Omniglot](https://github.com/brendenlake/omniglot)

## People

* [Visual Wake Words](https://github.com/Mxbonn/visualwakewords)
* [GAID](https://www.ei.tum.de/mmk/verschiedenes/tum-gaid-database/)

## Face

* [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)
* [CelebA-HQ](https://github.com/tkarras/progressive_growing_of_gans)
* [CelebA-Spoof](https://github.com/Davidzhangyuanhan/CelebA-Spoof)
* [Extended Yale B](http://vision.ucsd.edu/~leekc/ExtYaleDatabase/ExtYaleB.html)
* [KaoKore](https://github.com/rois-codh/kaokore)
* [LAOFIW](https://www.robots.ox.ac.uk/~vgg/data/laofiw/)
* [iCartoonFace](https://github.com/luxiangju-PersonAI/iCartoonFace)
* [LFW](http://vis-www.cs.umass.edu/lfw/)
* [VGG Face2](https://www.robots.ox.ac.uk/~vgg/data/vgg_face/)
* [Adience](https://talhassner.github.io/home/projects/Adience/Adience-data.html)
* [CASIA-FASD](https://pypi.org/project/bob.db.casia-fasd/)
* [CASIA-SURF](https://sites.google.com/qq.com/face-anti-spoofing/welcome/challengecvpr2019?authuser=0)
* [CASIA-Webface](https://github.com/happynear/AMSoftmax/issues/18)
* [Color FERET](https://catalog.data.gov/dataset/color-feret-database)
* [Replay-Mobile](https://www.idiap.ch/dataset/replay-mobile)
* [FairFace](https://github.com/joojs/fairface)
* [IMDb-Face](https://github.com/fwang91/IMDb-Face)
* [RFW](http://whdeng.cn/RFW/testing.html)
* [WebCaricature](https://cs.nju.edu.cn/rl/WebCaricature.htm)
* [QMUL-SurvFace](https://qmul-survface.github.io/)
* [DFW](http://iab-rubric.org/resources/dfw.html)
* [KANFace](https://sites.google.com/view/kanface-dataset)
* [MeGlass](https://github.com/cleardusk/MeGlass)
* [RMFD](https://github.com/X-zhangyang/Real-World-Masked-Face-Dataset)
* [DiveFace](https://github.com/BiDAlab/DiveFace)
* [Curated AFD](https://github.com/vitoralbiero/afd_dataset_cleaned)
* [LSLF]()
* [WildestFaces](https://ycbilge.github.io/wildestFaces)
* [IJB-A](https://www.nist.gov/programs-projects/face-challenges)


## Document

* [WOS](https://data.mendeley.com/datasets/9rw3vkcfy4/6)
* [Book Cover](https://github.com/uchidalab/book-dataset)
* [Processed Twitter](https://github.com/xguo7/MDCC-for-open-world-recognition)

## Clothing

* [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist)
* [Clothing1M](https://github.com/Cysu/noisy_label)
* [UT Zappos50K](http://vision.cs.utexas.edu/projects/finegrained/utzap50k/)
* [Atlas](https://github.com/vumaasha/atlas)
* [Exact Street2Shop](http://tamaraberg.com/street2shop/)
* [iMaterialist](https://github.com/visipedia/imat_fashion_comp)


## Scene

* [Places](http://places.csail.mit.edu/)
* [Places205](http://places.csail.mit.edu/downloadData.html)
* [Places365](http://places2.csail.mit.edu/)
* [Oxford Buildings](https://www.robots.ox.ac.uk/~vgg/data/oxbuildings/)
* [Million-AID](https://captain-whu.github.io/DiRS/)
* [Sun Attribute](https://cs.brown.edu/~gmpatter/sunattributes.html)
* [EGO-CH](https://iplab.dmi.unict.it/EGO-CH/)
* [LSUN](https://www.yf.io/p/lsun)

## Vehicles

* [Stanford Cars](https://ai.stanford.edu/~jkrause/cars/car_dataset.html)
* [FGVC-Aircraft](https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/)
* [N-CARS](https://www.prophesee.ai/2018/03/13/dataset-n-cars/)

## Flowers

* [Oxford 102 Flower](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/)

## Logo

* [Logo-2K+](https://github.com/msn199959/Logo-2k-plus-Dataset)
* [METU Trademark](http://kovan.ceng.metu.edu.tr/LogoDataset/)

## Food

* [FoodX-251](https://github.com/karansikka1/iFood_2019)
* [Food-101](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/)
* [Grocery Store](https://github.com/marcusklasson/GroceryStoreDataset)
* [Freiburg Groceries](http://aisdatasets.informatik.uni-freiburg.de/freiburg_groceries_dataset/)
* [KenyanFood13](https://github.com/monajalal/Kenyan-Food)
* [ISIA Food-500](http://123.57.42.89/FoodComputing-Dataset/ISIA-Food500.html)
* [Recipe1M+](http://im2recipe.csail.mit.edu/)
* [ChineseFoodNet](https://sites.google.com/view/chinesefoodnet)

## Animals

* [Caltech-UCSD Birds-200-2011](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html)
* [STL-10](https://cs.stanford.edu/~acoates/stl10/)
* [iNaturalist](https://github.com/visipedia/inat_comp/tree/master/2017)
* [IP102](https://github.com/xpwu95/IP102)
* [DIB-10K](https://github.com/RobinDong/birds_classification)

## 3D

* [smallNORB](https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/)

## Medical

* [LAG](https://github.com/smilell/AG-CNN)
* [EyeQ](https://github.com/hzfu/EyeQ)
* [PlantDoc](https://github.com/pratikkayal/PlantDoc-Dataset)
* [Cervix93 Cytology](https://github.com/parham-ap/cytology_dataset)
* [LKS](https://github.com/cradleai/LKS-Dataset)
* [ChestX-ray8](https://nihcc.app.box.com/v/ChestXray-NIHCC)
* [CheXpert](https://stanfordmlgroup.github.io/competitions/chexpert/)

## Aerial

* [MLRSNet](https://github.com/cugbrs/MLRSNet)

## Visual-Audio

* [VGG-Sound](https://www.robots.ox.ac.uk/~vgg/data/vggsound/)
* [TAU Urban Acoustic Scenes](https://zenodo.org/record/2589280)

## Others

* [DeepScores](https://tuggeluk.github.io/deepscores/)
* [11k Hands](https://sites.google.com/view/11khands)
* [EuroSAT](https://github.com/phelber/eurosat)
* [Stylized-ImageNet](https://github.com/rgeirhos/Stylized-ImageNet)
* [MINC](http://opensurfaces.cs.cornell.edu/publications/minc/)
* [BigEarthNet](https://www.tensorflow.org/datasets/catalog/bigearthnet)
* [AI2D](https://github.com/allenai/dqa-net)
* [Urban Environments](https://github.com/adrianalbert/urban-environments)
* [LaMem](http://memorability.csail.mit.edu/index.html)
* [BCN-2000](https://challenge2019.isic-archive.com/data.html)
* [AIDER](https://zenodo.org/record/3888300)
* [MAMe](https://github.com/HPAI-BSC/MAMe-baselines)
* [Vistas-NP](https://github.com/matejgrcic/Vistas-NP)
* [DTD](https://www.robots.ox.ac.uk/~vgg/data/dtd/)