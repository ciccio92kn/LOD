# Object Detection Datasets

## General

* [COCO](https://cocodataset.org/)
* [KITTI](http://www.cvlibs.net/datasets/kitti/)
* [Visual Genome](https://visualgenome.org/)
* [nuScenes](https://www.nuscenes.org/)
* [LVIS](https://www.lvisdataset.org/)
* [OpenImages](https://storage.googleapis.com/openimages/web/index.html)
* [Objects365](https://www.objects365.org/overview.html)
* [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/)
* [SPair-71k](http://cvlab.postech.ac.kr/research/SPair-71k/)
* [ExDark](https://github.com/cs-chan/Exclusively-Dark-Image-Dataset)
* [FSOD](https://github.com/fanq15/Few-Shot-Object-Detection-Dataset)

## People

* [Crowd Human](http://www.crowdhuman.org/)
* [INRIA Person](http://pascal.inrialpes.fr/data/human/)
* [ETH](https://data.vision.ee.ethz.ch/cvl/aess/dataset/)
* [EuroCity Persons](https://eurocity-dataset.tudelft.nl/)
* [PeopleArt](https://github.com/BathVisArtData/PeopleArt)
* [TinyPerson](http://vision.ucas.ac.cn/resource.asp)
* [WiderPerson](http://www.cbsr.ia.ac.cn/users/sfzhang/WiderPerson/)
* [Human Parts](https://github.com/xiaojie1017/Human-Parts)
* [MobilityAids](http://mobility-aids.informatik.uni-freiburg.de/)
* [MOT17Det](https://motchallenge.net/data/MOT17Det/)
* [MOT20Det](https://motchallenge.net/data/MOT20Det/)

## Face

* [MALF](http://www.cbsr.ia.ac.cn/faceevaluation/)
* [FDDB](http://vis-www.cs.umass.edu/fddb/)
* [FDDB-360](https://researchdata.sfu.ca/islandora/object/sfu:2722)
* [UMDFaces](https://www.umdfaces.io/)
* [300W](https://ibug.doc.ic.ac.uk/resources/300-W/)

## Logo

* [LogoDet-3K](https://github.com/Wangjing1551/LogoDet-3K-Dataset)
* [BelgaLogos](http://www-sop.inria.fr/members/Alexis.Joly/BelgaLogos/BelgaLogos.html)

## Indoor

* [Sun RGB-D](https://rgbd.cs.princeton.edu/)
* [SceneNet](https://robotvault.bitbucket.io/)
* [InteriorNet](https://interiornet.org/)

## Outdoor

* [Waymo Open](https://waymo.com/open)
* [Synscapes](https://7dlabs.com/synscapes-overview)

## Objects

* [SKU-110K](https://github.com/eg4000/SKU110K_CVPR19)
* [METU-ALET](https://github.com/metu-kovan/METU-ALET)
* [SKU-100K-R](https://github.com/Anymake/DRN_CVPR2020)
* [ARID](https://www.acin.tuwien.ac.at/en/vision-for-robotics/software-tools/autonomous-robot-indoor-dataset/)
* [UDA-CH](https://iplab.dmi.unict.it/EGO-CH-OBJ-UDA/#dataset)

## Food

* [MinneApple](https://github.com/nicolaihaeni/MinneApple)
* [RPC](https://rpc-dataset.github.io/)
* [Oktoberfest Food](https://github.com/a1302z/OktoberfestFoodDataset)

## Aerial

* [DOTA](https://captain-whu.github.io/DOTA/)
* [xView](http://xviewdataset.org/)
* [UAVDT](https://sites.google.com/view/grli-uavdt/%E9%A6%96%E9%A1%B5)
* [COWC](https://gdo152.llnl.gov/cowc/)
* [fMoW](https://github.com/fMoW/dataset)
* [VisDrone](https://github.com/VisDrone/VisDrone-Dataset)
* [SpaceNet](https://spacenet.ai/)
* [MOR-UAV](https://visionintelligence.github.io/Datasets.html#)


## 3D

* [PASCAL3D+](https://cvgl.stanford.edu/projects/pascal3d.html)
* [H3D](https://usa.honda-ri.com/H3D)
* [Washington RGB-D](https://rgbd-dataset.cs.washington.edu/)
* [WoodScape](https://github.com/valeoai/WoodScape)
* [FAT](https://research.nvidia.com/publication/2018-06_Falling-Things)
* [Kitchen Scenes](https://cs.gmu.edu/~robot/gmu-kitchens.html)
* [SIDOD](https://research.nvidia.com/publication/2019-06_SIDOD%3A-A-Synthetic)
* [ScanRefer](https://github.com/daveredrum/ScanRefer)

## Text

* [PubLayNet](https://github.com/ibm-aur-nlp/PubLayNet)
* [IIIT-AR-13K](http://cvit.iiit.ac.in/usodi/iiitar13k.php)
* [ICDAR 2013](https://rrc.cvc.uab.es/?ch=2)


## Animals

* [IP102](https://github.com/xpwu95/IP102)

## Medical

* [PlantDoc](https://github.com/pratikkayal/PlantDoc-Dataset)


## Others

* [CCPD](https://github.com/detectRecog/CCPD)
* [CURE-TSD](https://github.com/olivesgatech/CURE-TSD)
* [SoccerDB](https://github.com/newsdata/SoccerDB)
* [Stream-51](https://github.com/tyler-hayes/Stream-51)
* [Retail50K](https://github.com/clobotics/piou)
* [FedVision-Street](https://dataset.fedai.org/#/datasetfed)
* [TJU-DHD](https://github.com/tjubiit/TJU-DHD)
